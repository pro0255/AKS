{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 23.3. Dictionary coding I - 10 points\n",
    "\n",
    "- Compress and decompress files from Lab 1. using LZ77 or LZSS (7pts)\n",
    "- Try different sizes of the sliding window: 4kB, 16kB, 32kB and lengths of the uncompressed part. (1pt)\n",
    "- Try to compute zero order entropy of each field in a token and use it to compute approximate final compressed file size. (1pt)\n",
    "- Compute the length of the output file and prepare a report summarizing the results. (1pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compress and decompress files from Lab 1. using LZ77 or LZSS (7pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "def adding_module_path():\n",
    "    module_path = os.path.abspath(os.path.sep.join([\"..\"]*2))\n",
    "\n",
    "    if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "\n",
    "adding_module_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.load_data import get_dataset\n",
    "from src.load_data import DataSets\n",
    "from src.get_probs import get_sorted_probs_as_df\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from src.types.table_types import Fields\n",
    "from src.save import save_both\n",
    "from enum import Enum\n",
    "import re\n",
    "from ast import literal_eval\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LZType(Enum):\n",
    "    LZ77 = \"LZ77\"\n",
    "    LZSS = \"LZSS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading C://Users//Vojta//Desktop//iv//AKS//datasets\\dna\\dna.50MB\n"
     ]
    }
   ],
   "source": [
    "data_dna, path_dna = get_dataset(DataSets.dna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"abbabbabbbaab\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LZ77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LZ77:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def encode(self, text):\n",
    "        items = []\n",
    "        unprocessed = text\n",
    "        processed = \"\"\n",
    "        while True:\n",
    "            pointer, match_length = None, None\n",
    "\n",
    "            if len(unprocessed) == 0:\n",
    "                break\n",
    "\n",
    "            if len(unprocessed) == 1:\n",
    "                current_item = {\n",
    "                    \"Processed\": processed + unprocessed,\n",
    "                    \"Unprocessed\": \"\",\n",
    "                    \"P\": 0,\n",
    "                    \"L\": 0,\n",
    "                    \"N\": unprocessed\n",
    "                }\n",
    "                items.append(current_item)\n",
    "                break\n",
    "\n",
    "\n",
    "            if len(items) == 0:\n",
    "                pointer, match_length, match_text = self.find_longest_match(None, unprocessed)\n",
    "            else:\n",
    "                last_item = items[-1]\n",
    "                pointer, match_length, match_text = self.find_longest_match(last_item[\"Processed\"], last_item[\"Unprocessed\"])\n",
    "            \n",
    "\n",
    "            next_symbol = unprocessed[match_length]\n",
    "            processed +=  match_text + next_symbol\n",
    "            unprocessed = unprocessed[match_length+1:]\n",
    "            \n",
    "\n",
    "            current_item = {\n",
    "                \"Processed\": processed,\n",
    "                \"Unprocessed\": unprocessed,\n",
    "                \"P\": pointer,\n",
    "                \"L\": match_length,\n",
    "                \"N\": next_symbol\n",
    "            }\n",
    "\n",
    "            items.append(current_item)\n",
    "        return items\n",
    "\n",
    "    def find_longest_match(self, text_processed, text_unprocessed):\n",
    "        #start of match\n",
    "        pointer = 0\n",
    "\n",
    "        #match length\n",
    "        match_length = 0\n",
    "\n",
    "        #text which is matched without replication\n",
    "        match_text = \"\"\n",
    "\n",
    "        if text_processed is None:\n",
    "            return pointer, match_length, match_text\n",
    "\n",
    "        for i in range(len(text_processed)):\n",
    "            sub_sequence = text_unprocessed[:i+1]\n",
    "\n",
    "            matches = [(match.span(), match.string[match.span()[0]:match.span()[1]])for match in re.finditer(sub_sequence, text_processed)]\n",
    "            sorted_matches = list(sorted(matches, key=lambda x: x[0][0], reverse=True))\n",
    "\n",
    "\n",
    "            if len(sorted_matches) > 0:\n",
    "                last = sorted_matches[0]\n",
    "                span, text = last\n",
    "                start, end = span\n",
    "\n",
    "                if end == len(text_processed):\n",
    "                    #try replicate\n",
    "                    test_length = 0\n",
    "                    while True:\n",
    "                        current_char = text[test_length % len(text)]\n",
    "                        if current_char == text_unprocessed[test_length]:\n",
    "                            test_length += 1\n",
    "                        else:\n",
    "                            break\n",
    "\n",
    "                    #maybe equal?\n",
    "                    if test_length > match_length:\n",
    "                        match_length = test_length\n",
    "                        pointer = len(text_processed) - start\n",
    "                        match_text = text_unprocessed[0:test_length]\n",
    "                else:\n",
    "                    if len(text) > match_length:\n",
    "                        match_length = len(text)\n",
    "                        pointer = len(text_processed) - start\n",
    "                        match_text = text_unprocessed[0:len(text)]\n",
    "\n",
    "\n",
    "        return pointer, match_length, match_text\n",
    "\n",
    "    def create_from_triplets_code(self, triplets):\n",
    "        return \";\".join(str((x[\"P\"], x[\"L\"], x[\"N\"])) for x in triplets)\n",
    "\n",
    "    def create_from_code_triplets(self, code):\n",
    "        return code.split(';')\n",
    "\n",
    "    def tiplets_to_table(self, triplets):\n",
    "        return pd.DataFrame(triplets)\n",
    "    \n",
    "    def decode(self, triplets):\n",
    "        processed = \"\"\n",
    "\n",
    "        for triplet in triplets:\n",
    "            new_processed = processed\n",
    "            pointer, sequnce_length, next_symbol = literal_eval(triplet)\n",
    "\n",
    "            if pointer == 0 and sequnce_length == 0:\n",
    "                new_processed += next_symbol\n",
    "                processed = new_processed\n",
    "                continue\n",
    "            \n",
    "            i = pointer\n",
    "            counter = 0\n",
    "            while counter < sequnce_length:\n",
    "                new_processed += processed[-i]\n",
    "                counter += 1\n",
    "                i -= 1\n",
    "                if i == 0:\n",
    "                    i = pointer\n",
    "\n",
    "            new_processed += next_symbol\n",
    "            processed = new_processed\n",
    "\n",
    "\n",
    "        return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = LZ77()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 5, 'bbabb')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance.find_longest_match(\"abba\", \"bbabbbaab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets = instance.encode(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Processed</th>\n",
       "      <th>Unprocessed</th>\n",
       "      <th>P</th>\n",
       "      <th>L</th>\n",
       "      <th>N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>bbabbabbbaab</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ab</td>\n",
       "      <td>babbabbbaab</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abba</td>\n",
       "      <td>bbabbbaab</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abbabbabbb</td>\n",
       "      <td>aab</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abbabbabbbaa</td>\n",
       "      <td>b</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abbabbabbbaab</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Processed   Unprocessed  P  L  N\n",
       "0              a  bbabbabbbaab  0  0  a\n",
       "1             ab   babbabbbaab  0  0  b\n",
       "2           abba     bbabbbaab  1  1  a\n",
       "3     abbabbabbb           aab  3  5  b\n",
       "4   abbabbabbbaa             b  4  1  a\n",
       "5  abbabbabbbaab                0  0  b"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance.tiplets_to_table(triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = instance.create_from_triplets_code(triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(0, 0, 'a');(0, 0, 'b');(1, 1, 'a');(3, 5, 'b');(4, 1, 'a');(0, 0, 'b')\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets = instance.create_from_code_triplets(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = instance.decode(triplets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test if works correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded == test_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LZSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_text = \"abbabbabbbaab\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LZSS:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def encode(self, text):\n",
    "        items = []\n",
    "        unprocessed = text\n",
    "        processed = \"\"\n",
    "        while True:\n",
    "            pointer, match_length = None, None\n",
    "\n",
    "            if len(unprocessed) == 0:\n",
    "                break\n",
    "\n",
    "            if len(unprocessed) == 1:\n",
    "                current_item = {\n",
    "                    \"Processed\": processed + unprocessed,\n",
    "                    \"Unprocessed\": \"\",\n",
    "                    \"Output\": (0, unprocessed)\n",
    "                }\n",
    "                items.append(current_item)\n",
    "                break\n",
    "\n",
    "\n",
    "            if len(items) == 0:\n",
    "                pointer, match_length, match_text = self.find_longest_match(None, unprocessed)\n",
    "            else:\n",
    "                last_item = items[-1]\n",
    "                pointer, match_length, match_text = self.find_longest_match(last_item[\"Processed\"], last_item[\"Unprocessed\"])\n",
    "            \n",
    "            if pointer == 0:\n",
    "                next_symbol = unprocessed[match_length]\n",
    "                processed += next_symbol\n",
    "                unprocessed = unprocessed[match_length+1:]\n",
    "                current_item = {\n",
    "                    \"Processed\": processed,\n",
    "                    \"Unprocessed\": unprocessed,\n",
    "                    \"Output\": (0, next_symbol)\n",
    "                }\n",
    "                items.append(current_item)\n",
    "\n",
    "            else:\n",
    "                processed +=  match_text\n",
    "                unprocessed = unprocessed[match_length:]\n",
    "                \n",
    "                current_item = {\n",
    "                    \"Processed\": processed,\n",
    "                    \"Unprocessed\": unprocessed,\n",
    "                    \"Output\": (1, pointer, match_length)\n",
    "                }\n",
    "                items.append(current_item)\n",
    "            \n",
    "        return items\n",
    "\n",
    "    def find_longest_match(self, text_processed, text_unprocessed):\n",
    "        #start of match\n",
    "        pointer = 0\n",
    "\n",
    "        #match length\n",
    "        match_length = 0\n",
    "\n",
    "        #text which is matched without replication\n",
    "        match_text = \"\"\n",
    "\n",
    "        if text_processed is None:\n",
    "            return pointer, match_length, match_text\n",
    "\n",
    "        for i in range(len(text_processed)):\n",
    "            sub_sequence = text_unprocessed[:i+1]\n",
    "\n",
    "            matches = [(match.span(), match.string[match.span()[0]:match.span()[1]])for match in re.finditer(sub_sequence, text_processed)]\n",
    "            sorted_matches = list(sorted(matches, key=lambda x: x[0][0], reverse=True))\n",
    "\n",
    "\n",
    "            if len(sorted_matches) > 0:\n",
    "                last = sorted_matches[0]\n",
    "                span, text = last\n",
    "                start, end = span\n",
    "\n",
    "                if end == len(text_processed):\n",
    "                    #try replicate\n",
    "                    test_length = 0\n",
    "                    while True:\n",
    "                        current_char = text[test_length % len(text)]\n",
    "                        if current_char == text_unprocessed[test_length]:\n",
    "                            test_length += 1\n",
    "                        else:\n",
    "                            break\n",
    "\n",
    "                    #maybe equal?\n",
    "                    if test_length > match_length:\n",
    "                        match_length = test_length\n",
    "                        pointer = len(text_processed) - start\n",
    "                        match_text = text_unprocessed[0:test_length]\n",
    "                else:\n",
    "                    if len(text) > match_length:\n",
    "                        match_length = len(text)\n",
    "                        pointer = len(text_processed) - start\n",
    "                        match_text = text_unprocessed[0:len(text)]\n",
    "\n",
    "\n",
    "        return pointer, match_length, match_text\n",
    "\n",
    "    def create_from_triplets_code(self, triplets):\n",
    "        return \";\".join(str((x[\"Output\"])) for x in triplets)\n",
    "\n",
    "    def create_from_code_triplets(self, code):\n",
    "        return code.split(';')\n",
    "\n",
    "    def tiplets_to_table(self, triplets):\n",
    "        return pd.DataFrame(triplets)\n",
    "    \n",
    "    def decode(self, triplets):\n",
    "        processed = \"\"\n",
    "\n",
    "        for triplet in triplets:\n",
    "            new_processed = processed\n",
    "            tup = literal_eval(triplet)\n",
    "\n",
    "            if tup[0] == 0:\n",
    "                flag, next = tup\n",
    "                new_processed += next\n",
    "                processed = new_processed\n",
    "                continue\n",
    "\n",
    "            else:\n",
    "                flag, pointer, sequnce_length = tup\n",
    "\n",
    "                i = pointer\n",
    "                counter = 0\n",
    "                while counter < sequnce_length:\n",
    "                    new_processed += processed[-i]\n",
    "                    counter += 1\n",
    "                    i -= 1\n",
    "                    if i == 0:\n",
    "                        i = pointer\n",
    "\n",
    "                processed = new_processed\n",
    "\n",
    "\n",
    "        return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = LZSS()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 2, 'ab')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance.find_longest_match(\"abbabbabbbba\", \"ab\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets = instance.encode(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Processed</th>\n",
       "      <th>Unprocessed</th>\n",
       "      <th>Output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>bbabbabbbaab</td>\n",
       "      <td>(0, a)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ab</td>\n",
       "      <td>babbabbbaab</td>\n",
       "      <td>(0, b)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>abb</td>\n",
       "      <td>abbabbbaab</td>\n",
       "      <td>(1, 1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abbabbabb</td>\n",
       "      <td>baab</td>\n",
       "      <td>(1, 3, 6)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abbabbabbba</td>\n",
       "      <td>ab</td>\n",
       "      <td>(1, 4, 2)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>abbabbabbbaab</td>\n",
       "      <td></td>\n",
       "      <td>(1, 5, 2)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Processed   Unprocessed     Output\n",
       "0              a  bbabbabbbaab     (0, a)\n",
       "1             ab   babbabbbaab     (0, b)\n",
       "2            abb    abbabbbaab  (1, 1, 1)\n",
       "3      abbabbabb          baab  (1, 3, 6)\n",
       "4    abbabbabbba            ab  (1, 4, 2)\n",
       "5  abbabbabbbaab                (1, 5, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#chyba v prezentaci v poslednim radku :((\n",
    "\n",
    "instance.tiplets_to_table(triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = instance.create_from_triplets_code(triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"(0, 'a');(0, 'b');(1, 1, 1);(1, 3, 6);(1, 4, 2);(1, 5, 2)\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets = instance.create_from_code_triplets(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoded = instance.decode(triplets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test if works correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoded == test_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading C://Users//Vojta//Desktop//iv//AKS//datasets\\dna\\dna.50MB\n"
     ]
    }
   ],
   "source": [
    "data_dna, path_dna = get_dataset(DataSets.dna)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading C://Users//Vojta//Desktop//iv//AKS//datasets\\english\\english.50MB\n"
     ]
    }
   ],
   "source": [
    "data_english, path_english = get_dataset(DataSets.english)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zero order entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "\n",
    "def calc_freq(content):\n",
    "    c = Counter(list(content))\n",
    "    return c\n",
    "\n",
    "def calc_p(counter, n):\n",
    "    counter = dict(counter)\n",
    "    res = {}\n",
    "    for k, v in counter.items():\n",
    "        res[k] = v / n  \n",
    "    return res\n",
    "\n",
    "def get_n(counter):\n",
    "    counter = dict(counter)\n",
    "    return np.sum(list(counter.values()))\n",
    "\n",
    "def calc_H(p):\n",
    "    H = 0\n",
    "    for k, v in p.items():\n",
    "        #Shannon equation!\n",
    "        H += p[k] * math.log2(p[k])\n",
    "    return -H\n",
    "\n",
    "def zero_order_entropy(data):\n",
    "    counter = calc_freq(data)\n",
    "    n = get_n(counter)\n",
    "    p = calc_p(counter, n)\n",
    "    H = calc_H(p)\n",
    "    return H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try different sizes of the sliding window: 4kB, 16kB, 32kB and lengths of the uncompressed part. (1pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading C://Users//Vojta//Desktop//iv//AKS//datasets\\dna\\dna.50MB\n"
     ]
    }
   ],
   "source": [
    "defined_sizes = [4, 16, 32]\n",
    "\n",
    "instances = {\n",
    "    \"LZ77\": LZ77(),\n",
    "    \"LZSS\": LZSS()\n",
    "}\n",
    "\n",
    "datasets = [\n",
    "    #(*get_dataset(DataSets.english), DataSets.english), \n",
    "    (*get_dataset(DataSets.dna), DataSets.dna)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "for x in datasets:\n",
    "    print(len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(data, size, metric=10**3):\n",
    "    n = len(data)\n",
    "\n",
    "    size = size * metric\n",
    "    \n",
    "    windows = [data[x:((i+1) * size)] for i, x in enumerate(range(0, n, size))]\n",
    "\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GATCAATGAGGTGGACACCAGAGGCGGGGACTTGTAAATAACACTGGGCTGTAGGAGTGATGGGGTTCACCTCTAATTCTAAGATGGCTAGATAATGCATCTTTCAGGGTTGTGCTTCTATCTAGAAGGTAGAGCTGTGGTCGTTCAATAAAAGTCCTCAAGAGGTTGGTTAATACGCATGTTTAATAGTACAGTATGGTGACTATAGTCAACAATAATTTATTGTACATTTTTAAATAGCTAGAAGAAAAGCATTGGGAAGTTTCCAACATGAAGAAAAGATAAATGGTCAAGGGAATGGATATCCTAATTACCCTGATTTGATCATTATGCATTATATACATGAATCAAAATATCACACATACCTTCAAACTATGTACAAATATTATATACCAATAAAAAATCATCATCATCATCTCCATCATCACCACCCTCCTCCTCATCACCACCAGCATCACCACCATCATCACCACCACCATCATCACCACCACCACTGCCATCATCATCACCACCACTGTGCCATCATCATCACCACCACTGTCATTATCACCACCACCATCATCACCAACACCACTGCCATCGTCATCACCACCACTGTCATTATCACCACCACCATCACCAACATCACCACCACCATTATCACCACCATCAACACCACCACCCCCATCATCATCATCACTACTACCATCATTACCAGCACCACCACCACTATCACCACCACCACCACAATCACCATCACCACTATCATCAACATCATCACTACCACCATCACCAACACCACCATCATTATCACCACCACCACCATCACCAACATCACCACCATCATCATCACCACCATCACCAAGACCATCATCATCACCATCACCACCAACATCACCACCATCACCAACACCACCATCACCACCACCACCACCATCATCACCACCACCACCATCATCATCACCACCACCGCCATCATCATCGCCACCACCATGACCACCACCATCACAACCATCACCACCATCACAACCACCATCATCACTATCGCTATCACCACCATCACCATTACCACCACCATTACTACAACCATGACCATCACCACCATCACCACCACCATCACAACGATCACCATCACAGCCACCATCATCACCACCACCACCACCACCATCACCATCAAACCATCGGCATTATTATTTTTTTAGAATTTTGTTGGGATTCAGTATCTGCCAAGATACCCATTCTTAAAACATGAAAAAGCAGCTGACCCTCCTGTGGCCCCCTTTTTGGGCAGTCATTGCAGGACCTCATCCCCAAGCAGCAGCTCTGGTGGCATACAGGCAACCCACCACCAAGGTAGAGGGTAATTGAGCAGAAAAGCCACTTCCTCCAGCAGTTCCCTGTCTGAGCTGCTGTCCTTGGACTTGAAGAAGCTTCTGGAACATGCTGGGGAGGAAGGAAGACATTTCACTTATTGAGTGGCCTGATGCAGAACAGAGACCCAGCTGGTTCACTCTAGTTCGGACTAAAACTCACCCCTGTCTATAAGCATCAGCCTCGGCAGGATGCATTTCACATTTGTGATCTCATTTAACCTCCACAAAGACCCAGAAGGGTTGGTAACATTATCATACCTAGGCCTACTATTTTAAAAATCTAACACCCATGCAGCCCGGGCACTGAAGTGGAGGCTGGCCACGGAGAGAGCCAGGCAATCACTGGCTTTTCCTTAGACAGAGAGCTGGTTCCTAGGAGAAGAAGCTCCAGGCTGGGGTCCAGGCTATGACCCAACTGTTCAGTTTTGCAACATCCAGCATGGCTGCCTGATCAGGGGTGCATATGTCAGAGGAGCCTTCAGCTGGGAAGTGCTGACAAATGACCCAGACCTGACCTGCCCGATGCCAAGGCCTCCTTTAGTACATCCCATGGAGGACACTTGAGACAAAGTCACAGCTCAGCCCGTTGATTTCCCATGCTCTGACTGTGCGGTGCAGCAGGACCCCTAGCAGGCAGCATGTGTTCAAGGCAGCGATATCCAAATGCTATGAATTGCTGTCCTGATGGTTATTTTCCTGCATACAGTAGAGCTGATCCCTGTACAATGCTGGTCCTAAATCTCACCTTTGACAGTGCGCTGATGTGCAATGTTTGCTTTTGTTTTATTTGATGGAACATGGCTAATTGCTAAGAAGGTGACATGCTGCCCACTGACCACCCAATGTTCATTCTCCTCTTCTTCCTTACTAACAAAACTGCGGTGGTGGTGGTGAGGAGAGGGAGGGGGTATAACAAATGTGCCAAGCCAAGAGTTTATATTTGCAAGCCTCTCTTATACCTAGAGTTGATCGTGACACAGCTCTGGCCAATGATGTGTAAGCAGAAGTTGCTTGATGTGACTTCTGGCAAAGCTCTTAAGGAGAGGACTGACCTGTTTCCACATATCTTTTTCCTTTCCGTGTCCTTAGTCCTGGCTGGGATGCAGATGAGATGCAAAAGGTGGAGCAGCCATGTTGTCATCAGGCAGTAACAGGTCTGAGGGTAGAAGCTGCATTCTGATAATACCAGGGAAAAATAATACAAGTAGTCTAGGGCCCAGAGATATCACAGATGTCCATTTGAACCCCAAATTACCTGTCTCCAGATTTGCTATCAGGCAAGAAAAGGAAATCTTTCATTAGTTTAAGCTGTAGTTTACTCCAGTTTTCTATAACTTTCGGCCAGATATAACCCTAAATTGACAAAGGGGGCAAGTGCTTAACTGCAAAGCAGTTAAAACTCAAACACAGGCCTTCATTTCTTCAGGGTTTTAGTTTTTTCTAGGGAAGAATCTTAACTACTGCTACTAAAAGTTATAGTAGGCCAGGGATGGTGACTCACGCCTGTAATCTCAGCACTTTGGAAGCCCAGGCAGGTGGATCACCTGAGGTCAGGAGTTCAAGACCAGCCTGGCCAACGTGGTGAAACCCCATCTCTACTAAAAATACAAAAATTAGCCAGGCATGATGGTGCATGCCTGTAGTCACACCTACTCAGGAGGCTGAGTCAGGAGAATAGCTTGACCCAGGAGGCAGAGGTGGCAGTGAGCCAAGATCGCACCACTGCACTCCAGCCTGGGCGACAGAGCAAGACTCTGTCTCAAAAAAAAAAAAGTCATAATCAAAGAGGAAGACTGAGATAAATGTAGAGTCAAAGGGCTAAACAGAAACATAACACATGGGTTTTAAGCTAAGCCTTCACATTATCCCTTATACAATTTTATCTACACCGATTTCACCAAAGCTCAAAGTTATATTATTGGCTGAGATTGGCATTGGGATGGAGTGGTGAAGCTAAGAAATTCGTTATCCCTTTGTTCCAGTGCTGCTGGACTTTTCACTAAGTGAAGAGGTAAATGCTGAGTCTCCCAGGAGGCTGACTCCTCCTGGCTCTGGGTGTGCATTCTGATGAAGGTTCTTTATTGTAGGCACCAACAGAAGGCTCATGAGAGGGCAACATGGATCTCCATTTCTGAGCAGATGTTTAAACGCTGAATCAGGTCCAAGGCTTCCCAAATGAACTCAAGGAGTTTCTTTTTCCCAAGCCATAGAAAGTGGCGATAGCAATCCAGGGTCTGCACTGGGAAGGAGCACTGCCAGGACACGTCCCTCCCTGCCATTCCCCCACCCTCGCCCAGGAGACGTCCCTCCCTGCCACCACACAGGACACATCCCTCCTTGCCATCCCACCCCCCTTCCCAGGACACGTCCCTCCCTGCCATCCCATCCCATTCCCCCACAAGGACACGTCCCTCCCTGTCATCCCACCCCCCTTCTCAGGACACATCCTTCCCTGCCATCCCACACCCCCCCCAGGACACGTCCCTCCCTGCCATCCCACGCCTCCCCCCAGGACACATCCCTCCCTGCCATCCCACCCCGCCCCCCAGGACACACAGGTCCGTGAAATCAGTATAGACACTTGTATCAAGCAAGAAGAAGCATGTTACTCAGAAGAACACAATTTTGTTGTTTTGTTTTTGTTTCTG',\n",
       " 'GGTTTTGGTTGTTTTTTTTGTTTTTTTTTTTGGGGAATTAAACAAATAATTTCAAGTTCTACCTCCACCACCTACCAGCTGCATGATCTTAGACCATTGACATCACCTCCCTGACCGTGATTTTCACATCTAGAGAATGGGAGGGGAAGAACCATGCCTTGGGGGCCAGGCTGAGGATGAACTATGAAAACCCGTCCTATTGGGCACTCTCGAACAGTCACCATTGTTGGTATGAGGCCCACTATCAGTGAAACTGATTGAAATTGGTGTACATCTGAGACCTGAGGACAGCCATCAAGTGTCTATTAACTTAAGCTTTATGTAGCAAGCATTTATTGCACATGATCCTAGGTCCCAAGTATGCTTCGGTAAATTAAACACCCTTGGTCCCTGCCCTCACAAGCCGTTCATAATCTAGACAGATACATAAGATATAAATGCACAATTGTTCATTGAAAATCTCCGAAGTCACTGGCTATTTTCTGTGGTTCTCGGCACCATCACCACCCTTCCAAATTCTCTCCTGTTCTCAGGGGTTAGAAACCTGCAAACTACATTCCCTAGACTTCCTTGCCTGTAGGAGCAAAATGATCCCATGTATTACTGCGAAATGGTAGTGTCTGGGTCCCAGAAGACAGTTAGTAGAATCAGAATGTAGGAAAGTGTGTGCCACAGCCACACATGTTCATGATAGTCATAACTTGTTCAGTAGGAATTTAGAGAAGACTGACTGTACACAAGGTATTGCTAAATGCTATGCGGGATACAGAGATGCCTGTGCCTCTAAGAAACTTGGTAGAAAAATAATAACCCACACATATTTGGCTTACCTTCTCTTTGAATAGAGCAATTGGCAGTTTAGATTCAGTCATTCTTCAATTCATTTAGCCAAAATTTATTCTGTGATGGCTGAATCCAACAAATGAAGTCTCTACTCTCATATTATTTTCCATTTTGTTCCACTGAATTTCAGCAAACATAGACCAGACAAGCATCCCTTTGAAACCTGGACTTGGGATGAGGGTCTGCTGAGATTGGGTTTTCTCCATGCCCAGATGCCTCTGATCAAATATCAAGTCCCAAAGATACAGATGAGAAAGTTATTAAGTGTTCTGGGATTGGGACATCGGAGATATTAATTAACCCTGGCTTGAGATGGGAAGAGGGGGCAGGTAGCTTTCTTTGTGTAGTGTTTAGGAAGGTGATTGCCAATCTAGGAGAAGTGAGTTCCCCAGAGGGAGGGGGGCTCTTGGCCAGCAGGGTGACCCATATGTTCTGGTCTGCCTGGAGCTGTGGTCCTTGGGTTCACAGCGGCCCCTTTGCACTCAAAGCACCCTAGCTTGGACAATAAATTCTACAGTCAGTTCTGCAGTGACGATCTTCAATTCCTAGGGCTGCCATAAGAGAAGATCATAGACTAGGGGTGGTACACGACAGAAATTCATCTTCTCCCAGTTCTGGAGCCTGAAAATCCAAAACAAGGTGCTGTCAGGGTTGGATTCTCCTTGGGCCTCTCTTCTTGGCTTGCAGGTGGCTGTCTTCTGGCTGTGTCCTCGTGTGTCCCCAACATCCCCCTGTGTGTGTGTGCAACCCTTATGTCTCTTCCTCTGCTCATAAGAAAACAGTCCTATAGGACTAGGACCACATTCTTATGGCCTCATTTAACCTTAATTACCTCCTTTAGGGCCCTGTCTCCAAATATGTTCAGTGGAGGTTTGGGGCTTTGGCATATGAGTCTTTGGAGGCCACAGTTCTGTCCAGAACACACTGACCCTATCCACCAGGTACTGCCACACCAATGGCTTTCAGCATTAGACAGAGCCCCCCTGGGCTCTGTAACCCCACCCAGGGTGTTAAGAATGAGGAGTGAAAGTCCACACATGTACACACATGTTAATAGCAGCATTATGCGCAACAGTCAAACAGTGGACACACCCAAATGCCCATCAGTGGATGATGGATACATGCAAGGTGATTTATCCAGACAGTGGCATCATATTCTGTGGCCGGAAACAGGAGGGGAACGCTGACACTTGGCACAACACGGAAGACCTTTGAAAACATATTGCAGCAGATTGAATGAAAAAACAGAGAGAAGAATCCAGCCGCCTCATATAATTTCTTTTTAACTTGCAAATGTTATTTTTAATCAAAATGTTATTTACATGGCACTGAGTGTACGGACAACCTTTGAAAACATGGTGCTGAGTGTAAGAACCAAACAGGAAAGGCCACGTGTTGTTCATTGATAGGAAATGTCCAGAATAGGATGTTCTAAAGAGACTGAGAATGGATAAGTGGCTGCTTAAGTGGGGGGGTGGAAGGAGGATAGAAGAGTGATAGCTAAAGGGCACAGTTTCTTTCTGAGGTGATGGTATGTTCCAAAATTGACATTGGTGATGGTTGCACACACTGCAGATACACCAAAATCCACCAAGTTAAATTGAAATGCACACTTTACACTATTGAATTATATACTTTAAGTGGCTGAATTGTATAGCATATGAATTACATTTCAATAAAGCCTTTTAAATAAATCATGCATGGGTAAAATGTCCACTCAAAGTAAGATAAACCAGCGCATTGTAATGTAATAGAGTACAAAATGCATGGGTATGGAATTCCACTTACAACCCATCATTAATCAACCACTACTTATCAAAGAAACCCCAACTTGTCAAATTTCAGTGTGATGTCAAACAAGATACCCAGTGTTACCTGAGAAGGCTAGTAAGACACTCATCTCTTTTCAAACTACTTGGAAGTATGAGGCCAGGTTCTTTTCCTATTCTTCAACCAAAACAATGTATTGCAACAGATTGAATGAAAAAAACAGAGAGAAGAATCCAGCTGCCTCATGTAATTTCTTTTTAATTTGGAAATGGTATTTTTAATCAAAATGTTATTTACATTAGCAATAATAATTTTTTTTAAAAAAGAATGAGGCTTGAGACGGAGACTCAGTGGCTGTGTCTACCGGCCTCAGTTGTAAAACAAGCACTGTTCATCCCGAGCCGACATAGCTGCTCATTCACTCATTCAAAAATAATCTTTGAACACCCGCTCTGTGATGAGGTGATGATGATGATGACGATGATGATGGTATCAGTACTGGCTAATATAATAAACTAGCTACTATGTGCCAAATGGTTTCTCAATCTGAGCCATTTAACCCCCACAGCAGCCCTGGAAAGTAAGAATCGTTACTAGCTCTAGGAGGCAGCCCCAGGGATAGGTCTGCGGTGCGTGTTCCAGAGTCGGGAGCCCTGGCCGAGGTCTGCGCTGGCTTTTTCCTCCCTGGGTGACCTGCACAAGAGGCAGGAGGTTAGCTGTCTGCTGCTACGGCTAACACACAGGCTCTCCTCATGGGGCTTGGGGAGGTGGATAAATTACTGTTCCTAATGTTTTTAGTGTGACTGAAGTGCTGGCCACTCAGTCACTCGTTTGCCCTTTCACTCATTCATTCATTCCTTCATTCAGTGATATATGAAGTGCCCACCGTGAGCCAGAGTGAGACGCTTTCCTGAGATCCCAGGATTTCTTAAACAAAATACACAAAGCACTTACGTAAAAGATCGATACACTGATTGCATTAAAATTAAGAACTTCTGTTTATCAAAAATTCCTTCAAGAAAATGAAGACAAGCTACAAACTGGGAGAAGATATTTCCAACATGTGTAATTGAAAAAACATTAATATTAATTATATATATATATGTGTACGTATATAATGTGTATATATGTGTGTGTGTGTATGTATATTTTCATATTTAAAACCAGACATCATTAATGCAAAGATAAATGCACCAATCAGAAAGTGAACAAAAATATAGAAACAGACATTTCACAAGAGAGAAAATATAGCTGGCCAATAAACATTTGAAGAAAAACCCAACTTAATTAGTAATTAGGTTAAGTGAAAAAAAGCAAGTACCGGAAGACTACATGCAGCATGATATTCTTTCTCAAAATAAAGGCTAGAAAATCAGATAAGATAAAT',\n",
       " 'AATATGCTCTGAGGCATCCATGTAGATATAACACAGCTATTTTCAGAGAAGGAATGATCAGCACTAACTTCTGTAGAAGTTTATAGGCACATGCAAGTTAGTTTGCTAGTTCCTGGGTGGCATGGTGGATTCATGGGAGTGCCTTGTGTTGTTAAAAATAAAGAAACTAGGCCTGGTTTGGTGGCTCATGCCTGAATCCCAACATTTTGGGAGGCTGAGAAGGAGGATTGCTTGAGCCCAGAAGTTTGAGACCAGCCTGGACAACGTGGTGAAACCCGTCTCTACAAAAATACAAAAATTAGCTGGGTGTGGTGGTGCACACCTGTGGTCCCAGCTACTTGGCAGCCTGAGGTGGGAGGTACACTTGAGGCCAGGAGGTCAAAGCTGCAATAAGCCGAGATCACCCCACTGTACTCCAGTCTTGGTGATAGAGTGAGACCCTGTCTCAAAAAAATAAATAAATAAAATAAAGAAACTAAAAATAACAACAATGATGATAATAATAATAATAGACTAGGCACAGTGGTTTACACCTGTATTCCCAGCACTTTGGGAGGCCGAGGCAGGCAGATCACTTGAGGTCAGGAGTTGAAGATCAGCCTGGCCAACATGGCGAAACCTCGCCTCTACTAAAAATACAAAATTAGGCCCGGTGCGGTGGCTCACACCTGTAATCCCTGCACTTTGGGAGGCGAGGTGGGTGGATCACCTGAGGTCAGGAGTTCGAGGCCAGCCTGGCCAACATGGCGAAACCCTGTCTCTACTAAAAAAAAAAGAAAAAGAAAAAATTAGCCAGACGTGGTGGCGGGTGCCAGTAATCCCAGCTACTTGGGAGGCTGAGGGAGGAGAATTGCTTAAACCCCGGTAGGCAGAAGTTGCAGCGAGCCGAGATCACACCACTGCACTCCAGCCTGGGTGAAACGCTCTCTCAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGTCAGGAATGGTGGCATGCGCCTGTAATCCCAGCTACTTAGGAGGATGAGAATCACTTGAACCTGGGAGGCAGAGGCTGCAGTGAGCCAAGATAGTGCTACTGCACTCCAGCCTGGGCAACAGAGCTAGACTCTGTCTCAAAAAAATAGTAATAATAATAGCAAAAGAGGGCCAGGCATGGCTGGCGAGTCATGAACCCAGGCGTGGCATTCCTCAAATTATGTGCACCTAAAGTCTGCGAAGGGAAACAAACAAGAATTCAAAAAGCAAGACACCCCGGGGGTTCTCTGTCCTTCCTTCCCTGCACTCAGTCTGCGTCCTGAGCAGCAACAGTGCTGACCCCATAAGCCTCGGCCAGCAGGTAAGGGTCACCTTCTCTTCCCTGCACTGAGGTTCCCAATGGAGACCAGGAAGTGAAGTGATTTCTAAGGGTTTCCTGTGAGGTCAGGAATCAAGATGGAATCATTGCCTCATCCTCTGTTAACCAGAAAATTCTCTAAGCCAAACCCTCCCATAGCCTCTGGTCTCTTCACTCAGCCGAGGGTTCCCTTGTGTTTAGAGGGCAAGGTGGGCTCTGTTTCCTCCCACTGGGATGGAGGAGTCAGAAAACTCACCTTACCCCGTTTGCCCCCGACAGTGCCACGTTACAAAAGTTGCCCAACTTCCTTAAATAATCCTGTCACTTCCTCCTCATTTGCCTCTGACGCATGAGAGCCTGGGAAACCCCAAGTCGCTTGCTGTAGGGCCTGCAGGAGGGCCTCCACCCCGACCCTGCACAGGACAGGGGAAGGGAGAACACCCAGGGAACTGAATCTTGAAACGCACAAAGGGAACACCGTACGGCCGTCTTTTCAAGGCCATTTCCCACAGAGAGCGTGCAAAAATAAGTGTCCTGGCTGGAGAGCACATTCCAGCTCCAAAGGCTCTGTTCCTTTTACTTTCTCCCGCGATTACTCTTATTTTTCTGCAGCTCAACAAGGACGGTCCGCTGATGTGAGCATCTTGTGATTTCTCCCCCAGCGCAGCCTGCCTGGCAGCTTCCTGTGCTCCCAGCACGAAGTGGAAGATGACCTTCAGCCGGAGGAGGGAGCGCAGCGCGGATTAGAAGGACATGGCGCGGGGACTGGCCTGGTTGTTGGGGCGGGGACAGAAATCCATTTCCCTCGTTTTCCTCCACGCCAGTGTGGGCCACTTCCTGAGTCTCCGCACACACCAGTGTCTGAGGTTCTCACTGACCTGCTCCAAGGTGAGGGATTCCCCGTATTTGGGGCAGAACAGACGTTCCCACCCCGCAAGGCTGCAGTGCGGGACAGACACGTGGCCCGGCCCCGAGATGCTGCAGAATGTTTGTCCTGGATTTTAACACGTTTTCGTCCCTGGTGGTCCCAGCGGCTGCTGCCAGGGACTAAAACACCTTTGTCAGATTATCAGAAGGCCCCGGGAAGGGAGGGGAGAGCCCAAGATGAGAGCACTGCTTTACCCGAGGCCCTATTTCCGCACGAGAAACTTTTCTCAGCCTGATCGCATCCCGGCTTCTAAGAAGGGCCTGGTTCAGGCTTTCAGCCTGAAGCCGGAGAGCACGAATGAGCCCTCCCCTGACTTCAAAAATAAAATCCCGGTACAGTATGATCATCATGATTATTGTTACCATTATTACCAGCACTGCAATCATTTGTGCTCTGGCCCTTTCATCCCAGAATTTCAAAGCAGAATGCTTTATAAGGAGATGGCTATTCATTTGTTCAGCGAGAGGCATCCTTTGAAAATGGAGCTTTCAGACTCTTGATGAAAAAAAAAAAAAAAAAAAAACCTCTGATTTCCACTCAGCGTGATTAACCAGACAAGGGCTTTCCTGAGAATGAATGTGTCTGTTGAGTGGGGTCCAGACAATGAGGTCAGAGGCGAGCTCCCGAAACACTCCAGGAAGCAGCACCTCGGGTGTCCAAGCTTCTGAGACTCTCTGCAGCCCCCTCCCATGGTCACCGTCTTCTGAAGGGCTGTAGGATCGAAAGTCACAGGCGCACCGGCAGCAGAGCAGCATGGCTAAGCCACAGGTTCCGGCAGGTGGCTTGGGCTCAAACCCTGGCTTTGCATCTGAAATTCCAGCTGCATGTCCTCGGGCAAGTTACTTAACTGCTCTGTGCTTCAATTGCTGCTTCCATAAAATGGGGCTAATGATAGTTTCCACCTCTTGGTGGTTCTGTTAGCTGAGTCATCATAGGCCCTGCCCTGGAAGCAGCATTGGGCACAGAATAAGCTTTCAGTAAGTTACAGTGATGGGGGCCCTCCGCCGTGGGGATGCCACTCCCTGGCTTGAAATGCAACAAGGGCTCCCTGTTGCTCTGATAGGACGCAGATCCTCCGCACAGCACCAGAGGCTCTCCAGGGCCTGGCTCCTCTTTCCTCCGGGCGTGCTCCTTGGTACTCACCATTACATCGCCCGCTCCTTCCTCAGCGCTGCCATTGCCTCGTGTGCTCGTCCCCGAAGTCCTCTGTCCACCTCACTCACCCTTAGGCCCCTGCGTCGGCCAGCACTTCATCTTGGAGAGCTCCTCCTTGTACTCATGTCCCTTGGCCAACTTGCCCCAGTCCTTCAGGACTCCTGTGAGTGTCACCTCTCCTGAGAAGTTTCCCGACTTTCCTGTTTCGATTAGCTGGATCCCCTTCCAGTGCCACAGCCCATGGCAGGGTCTCCTCCTCCCCCTCTGCCGTCATCTTTCTTTTTCTCCTCCTCCTTCTTTTTCTGTTTCTCCCACTGGACCCCTCGTTCCCAGCAGGGCAGGCCTTGCCTCTGGCCATCTCAGTGCCTGGTTCTTGCAGATGCCCAGAGGCTGCCTGGGAAGCCACTCCCGGCTCCACGAGGGGTGCTGCAGCCTCAGCGTATACTTCGGTGTTTGAGAACAAGGTGATGTCCACACTTGTCAAGGAAGCTCTTTCCCTTCTATTGGGTGTTTTCGGGGTCAGAGCAGAGACCACAGGGGAGTCACATGCTGCCTGGCTCACCAGAGGTGCTGAGTCCCTGGTTATGGAGCAGATGG']"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "windows = create_windows(data_dna, 4)\n",
    "windows[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(instance, size, data, path_data, name_data):\n",
    "\n",
    "    instance_type = type(instance).__name__\n",
    "    windows = create_windows(data, size)\n",
    "    n = len(data)\n",
    "\n",
    "    all_tables = pd.DataFrame()\n",
    "    \n",
    "    tic = time.time()\n",
    "    for window_index, window in enumerate(windows):\n",
    "        \n",
    "        print(f'Window index {window_index}')\n",
    "        \n",
    "        current_triplets = instance.encode(window)\n",
    "        current_table = instance.tiplets_to_table(current_triplets)\n",
    "\n",
    "\n",
    "        all_tables = pd.concat([all_tables, current_table])\n",
    "    toc = time.time()\n",
    "\n",
    "    dic = compute_aprox_size(all_tables, instance_type)\n",
    "\n",
    "\n",
    "    des = {\n",
    "        Fields.Path.value: path_data,\n",
    "        Fields.Parameter.value: f\"{size}kB\",\n",
    "        Fields.Type.value: instance_type,\n",
    "        Fields.Original.value: n * 8,\n",
    "        Fields.Aprox.value: 0,\n",
    "        Fields.Calculation.value: toc - tic,\n",
    "        Fields.Name.value: name_data\n",
    "    }\n",
    "\n",
    "    return {\n",
    "        **des\n",
    "        **dic,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to compute zero order entropy of each field in a token and use it to compute approximate final compressed file size. (1pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_aprox_size(table, current_type):\n",
    "\n",
    "    if current_type == \"LZ77\":\n",
    "\n",
    "        p = table.P.values\n",
    "        l = table.L.values\n",
    "        n = table.N.values\n",
    "\n",
    "        p_H = zero_order_entropy(p)\n",
    "        l_H = zero_order_entropy(l)\n",
    "        n_H = zero_order_entropy(n)\n",
    "\n",
    "        size_P = len(p)\n",
    "        size_L = len(l)\n",
    "        size_N = len(n)\n",
    "\n",
    "        aprox_size_P = p_H * size_P\n",
    "        aprox_size_L = l_H * size_L\n",
    "        aprox_size_N = n_H * size_N\n",
    "\n",
    "        return {\n",
    "            \"p_H\": p_H,\n",
    "            \"l_H\": l_H,\n",
    "            \"n_H\": n_H,\n",
    "            \"size_P\": size_P,\n",
    "            \"size_L\": size_L,\n",
    "            \"size_N\": size_N,\n",
    "            \"aprox_size_P\": aprox_size_P,\n",
    "            \"aprox_size_L\": aprox_size_L,\n",
    "            \"aprox_size_N\": aprox_size_N,\n",
    "            Fields.Aprox.value: aprox_size_P + aprox_size_L + aprox_size_N\n",
    "        }\n",
    "\n",
    "\n",
    "    else:\n",
    "        output = table.Output.values\n",
    "\n",
    "        flags = []\n",
    "        pointers = []\n",
    "        lengths = []\n",
    "        nexts = []\n",
    "\n",
    "        for o in output:\n",
    "            if len(o) == 2:\n",
    "                flag, next = o\n",
    "\n",
    "                flags.append(flag)\n",
    "                nexts.append(next)\n",
    "\n",
    "            else:\n",
    "                flag, pointer, length = o\n",
    "\n",
    "                flags.append(flag)\n",
    "                pointers.append(pointer)\n",
    "                lengths.append(length)\n",
    "\n",
    "\n",
    "        flags_H = zero_order_entropy(flags)\n",
    "        nexts_H = zero_order_entropy(nexts)\n",
    "        pointers_H = zero_order_entropy(pointers)\n",
    "        lengths_H = zero_order_entropy(lengths)\n",
    "\n",
    "        size_Flags = len(flags)\n",
    "        size_Nexts = len(nexts)\n",
    "        size_Pointers = len(pointers)\n",
    "        size_Lengths = len(lengths)\n",
    "\n",
    "        aprox_size_Flags = flags_H * size_Flags\n",
    "        aprox_size_Nexts = nexts_H * size_Nexts\n",
    "        aprox_size_Pointers = pointers_H * size_Pointers\n",
    "        aprox_size_Lengths = lengths_H * size_Lengths\n",
    "\n",
    "        return {\n",
    "            \"flags_H\": flags_H,\n",
    "            \"nexts_H\": nexts_H,\n",
    "            \"pointers_H\": pointers_H,\n",
    "            \"lengths_H\": lengths_H,\n",
    "            \"size_Flags\": size_Flags,\n",
    "            \"size_Nexts\": size_Nexts,\n",
    "            \"size_Pointers\": size_Pointers,\n",
    "            \"size_Lengths\": size_Lengths,\n",
    "            \"aprox_size_Flags\": aprox_size_Flags,\n",
    "            \"aprox_size_Nexts\": aprox_size_Nexts,\n",
    "            \"aprox_size_Pointers\": aprox_size_Pointers,\n",
    "            \"aprox_size_Lengths\": aprox_size_Lengths,\n",
    "            Fields.Aprox.value: aprox_size_Flags + aprox_size_Nexts + aprox_size_Pointers + aprox_size_Lengths\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p_H': 1.7924812503605778,\n",
       " 'l_H': 1.4591479170272448,\n",
       " 'n_H': 1.0,\n",
       " 'size_P': 6,\n",
       " 'size_L': 6,\n",
       " 'size_N': 6,\n",
       " 'aprox_size_P': 10.754887502163466,\n",
       " 'aprox_size_L': 8.754887502163468,\n",
       " 'aprox_size_N': 6.0,\n",
       " 'Aprox': 25.509775004326933}"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance = LZ77()\n",
    "triplets = instance.encode(test_text)\n",
    "table = instance.tiplets_to_table(triplets)\n",
    "compute_aprox_size(table, type(instance).__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'flags_H': 0.9182958340544896,\n",
       " 'nexts_H': 1.0,\n",
       " 'pointers_H': 2.0,\n",
       " 'lengths_H': 1.5,\n",
       " 'size_Flags': 6,\n",
       " 'size_Nexts': 2,\n",
       " 'size_Pointers': 4,\n",
       " 'size_Lengths': 4,\n",
       " 'aprox_size_Flags': 5.509775004326937,\n",
       " 'aprox_size_Nexts': 2.0,\n",
       " 'aprox_size_Pointers': 8.0,\n",
       " 'aprox_size_Lengths': 6.0,\n",
       " 'Aprox': 21.509775004326936}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instance = LZSS()\n",
    "triplets = instance.encode(test_text)\n",
    "table = instance.tiplets_to_table(triplets)\n",
    "compute_aprox_size(table, type(instance).__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_all(instances, sizes, datasets):\n",
    "    res = {}\n",
    "    counter = 0\n",
    "    for data, path_data, name_data in datasets:\n",
    "        for k, v in instances.items():\n",
    "            for size in sizes:\n",
    "                print(name_data, k, size)\n",
    "                value = run(v, size, data, path_data, name_data)\n",
    "                res[counter] = value\n",
    "                counter += 1\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataSets.dna LZ77 4\n",
      "Window index 0\n"
     ]
    }
   ],
   "source": [
    "result = run_all(instances, defined_sizes, datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dataframe = pd.DataFrame.from_dict(result, orient=\"index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the length of the output file and prepare a report summarizing the results. (1pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graf odsud\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uložení do souboru pro načtení v results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_both(result_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "97e6c85832baaca9363ab02f06d99864db3184f5c282967bd7ef920b2fe63dcd"
  },
  "kernelspec": {
   "display_name": "Python 3.8.1 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
